Reference for the resource,"@article{wordnet,
  title={Introduction to WordNet: An on-line lexical database},
  author={Miller, George A and Beckwith, Richard and Fellbaum, Christiane and Gross, Derek and Miller, Katherine J},
  journal={International journal of lexicography},
  volume={3},
  number={4},
  pages={235--244},
  year={1990},
  publisher={Oxford University Press}
}","@inproceedings{wsj0,
  title={Collection and Analyses of WSJ-CSR Data at MIT},
  author={Phillips, Michael and Glass, James and Polifroni, Joseph and Zue, Victor},
  booktitle={Speech and Natural Language: Proceedings of a Workshop Held at Harriman, New York, February 23-26, 1992},
  year={1992}
}","@misc{datatang1,
        author = {Beijing DataTang Technology Co., Ltd},
        title = {{A}{I} data annotation data customization {D}atatang --- datatang.ai},
        howpublished = {\url{https://www.datatang.ai/annotation}},
        year = {},
        note = {[Accessed 25-Jun-2023]},
}","@article{aishell2,
  title={Aishell-2: Transforming mandarin asr research into industrial scale},
  author={Du, Jiayu and Na, Xingyu and Liu, Xuechen and Bu, Hui},
  journal={arXiv preprint arXiv:1808.10583},
  year={2018}
}","@misc{csj1,
        author = {Seiju Sugito, Kikuo Maekawa, Hanae Koiso, Kenya Nishikawa, Yoko Mabuchi        },
        title = {{D}ocuments - {C}orpus of {S}pontaneous {J}apanese --- clrd.ninjal.ac.jp},
        howpublished = {\url{https://clrd.ninjal.ac.jp/csj/en/document.html}},
        year = {2006},
        note = {[Accessed 25-Jun-2023]},
}","@article{hkustSpeech1,
  title={Hkust mandarin telephone speech, part 1},
  author={Fung, P and Huang, S and Graff, D},
  journal={LDC2005S15. Web download},
  year={2005}
}","@misc{hkust2,
        author = {Hong Kong University of Science and Technology},
        title = {{L}inguistic {D}ata {C}onsortium {C}atalog},
        howpublished = {\url{https://catalog.ldc.upenn.edu/docs/LDC2005S15/}},
        year = {2007},
        note = {[Accessed 25-Jun-2023]},
}","@article{jsut,
  title={JSUT corpus: free large-scale Japanese speech corpus for end-to-end speech synthesis},
  author={Sonobe, Ryosuke and Takamichi, Shinnosuke and Saruwatari, Hiroshi},
  journal={arXiv preprint arXiv:1711.00354},
  year={2017}
}","@misc{vox1,
        author = {Ken MacLean},
        title = {{F}ree {S}peech... {R}ecognition ({L}inux, {W}indows and {M}ac) - voxforge.org},
        howpublished = {\url{https://www.voxforge.org/}},
        year = {},
        note = {[Accessed 25-Jun-2023]},
}","@misc{aishell12,
  author       = ""Beijing Shell Shell Technology Co., Ltd"",
  title        = ""Open Source Mandarin Speech Corpus
[AISHELL-ASR0009-OS1]
Training and Test Data "",
  howpublished = ""online"",
  month        = ""Nov"",
  year         = ""2018"",
  note         = ""documentation"",

}","@misc{fishspeech,
        author = {David Graff, Shudong Huang, Ingrid Cartagena, Kevin Walker, Christopher Cieri},
        title = {{F}isher {S}panish {S}peech - {L}inguistic {D}ata {C}onsortium --- catalog.ldc.upenn.edu},
        howpublished = {\url{https://catalog.ldc.upenn.edu/LDC2010S01}},
        year = {2010},
        note = {[Accessed 25-Jun-2023]},
}","@misc{fishtrans,
        author = {David Graff, Shudong Huang, Ingrid Cartagena, Kevin Walker, Christopher Cieri},
        title = {Fisher Spanish - Transcripts},
        howpublished = {\url{https://catalog.ldc.upenn.edu/LDC2010T04}},
        year = {2010},
        note = {[Accessed 25-Jun-2023]},
}",,"@misc{calltrans1,
        author = {Barbara Wheatley},
        title = {{C}{A}{L}{L}{H}{O}{M}{E} {S}panish {T}ranscripts - {L}inguistic {D}ata {C}onsortium --- catalog.ldc.upenn.edu},
        howpublished = {\url{https://catalog.ldc.upenn.edu/LDC96T17}},
        year = {1997},
        note = {[Accessed 25-Jun-2023]},
}","@misc{librivox,
        author = {Hugh McGuire},
        title = { {L}ibri{V}ox | free public domain audiobooks  --- librivox.org},
        howpublished = {\url{https://librivox.org/}},
        year = {2005},
        note = {[Accessed 25-Jun-2023]},
}","@inproceedings{switchboard1,
  title={SWITCHBOARD: Telephone speech corpus for research and development},
  author={Godfrey, John J and Holliman, Edward C and McDaniel, Jane},
  booktitle={Acoustics, Speech, and Signal Processing, IEEE International Conference on},
  volume={1},
  pages={517--520},
  year={1992},
  organization={IEEE Computer Society}
}","@misc{ted,
        author = {TED Conferences LLC.},
        title = {translate transcribe --- ted.com},
        howpublished = {\url{https://www.ted.com/participate/translate/transcribe}},
        year = {2022},
        note = {[Accessed 25-Jun-2023]},
}","@misc{Lindalibrivox,
        author = {LibriVox, Linda Johnsonn},
        title = {Linda Johnsonn {L}ibri{V}ox --- librivox.org},
        howpublished = {\url{https://librivox.org/sections/readers/11049}},
        year = {2016},
        note = {[Accessed 25-Jun-2023]},
}","@inproceedings{cstr1,
  title={The voice bank corpus: Design, collection and data analysis of a large regional accent speech database},
  author={Veaux, Christophe and Yamagishi, Junichi and King, Simon},
  booktitle={2013 international conference oriental COCOSDA held jointly with 2013 conference on Asian spoken language research and evaluation (O-COCOSDA/CASLRE)},
  pages={1--4},
  year={2013},
  organization={IEEE}
}","@article{darpatimit,
  title={DARPA TIMIT acoustic-phonetic continous speech corpus CD-ROM. NIST speech disc 1-1.1},
  author={Garofolo, John S and Lamel, Lori F and Fisher, William M and Fiscus, Jonathan G and Pallett, David S},
  journal={NASA STI/Recon technical report n},
  volume={93},
  pages={27403},
  year={1993}
}","@misc{magnatune,
        author = {John Buckman},
        title = {{I}nformation: about {M}agnatune --- magnatune.com},
        howpublished = {\url{http://magnatune.com/info/}},
        year = {2003},
        note = {[Accessed 25-Jun-2023]},
}","@misc{freesound,
	author = {the Music Technology Group of Universitat Pompeu Fabra},
	title = {{F}reesound --- freesound.org},
	howpublished = {\url{https://freesound.org/}},
	year = {2005},
	note = {[Accessed 25-Jun-2023]},
}"
Another reference for the resource,,,"@misc{datatang2,
        author = {},
        title = {{P}apers with {C}ode - aidatatang_200zh {D}ataset --- paperswithcode.com},
        howpublished = {\url{https://paperswithcode.com/dataset/aidatatang-200zh}},
        year = {},
        note = {[Accessed 25-Jun-2023]},
}",,"@book{csj2,
   author         = ""国立国語研究所"",
   title         = ""日本語話し言葉コーパスの構築法"",
   publisher         = ""国立国語研究所"",
   year          = ""2006"",
   month         = ""mar""
}","@misc{hkustSpeech2,
        author = {Pascale Fung, Shudong Huang, David Graff},
        title = {Mandarin Chinese Conversational Telephone Speech & Transcripts, PART 1},
        howpublished = {\url{https://catalog.ldc.upenn.edu/docs/LDC2005S15/}},
        year = {2005},
        note = {[Accessed 25-Jun-2023]},
}",,,"@misc{vox2,
        author = {VoxForge},
        title = {{P}apers with {C}ode - {V}ox{F}orge {D}ataset},
        howpublished = {\url{https://paperswithcode.com/dataset/voxforge}},
        year = {2019},
        note = {[Accessed 25-Jun-2023]},
}",,,,\cite calltrans2,"@misc{calltrans2,
        author = {Barbara Wheatley},
        title = {{C}{A}{L}{L}{H}{O}{M}{E} {S}panish {T}ranscripts - {L}inguistic {D}ata {C}onsortium --- catalog.ldc.upenn.edu},
        howpublished = {\url{https://catalog.ldc.upenn.edu/docs/LDC96T17/}},
        year = {1997},
        note = {[Accessed 25-Jun-2023]},
}",,,,,"@misc{cstr2,
        author = {Junichi Yamagishi},
        title = { CSTR VCTK Corpus 
      English Multi-speaker Corpus for CSTR Voice Cloning Toolkit },
        howpublished = {\url{https://datashare.ed.ac.uk/bitstream/handle/10283/3443/README.txt?sequence=1&isAllowed=y}},
        year = {2019},
        note = {[Accessed 25-Jun-2023]},
}",,,
Another reference for the resource,,,"@misc{datatang3,
        author = {speechocean},
        title = {{T}he largest open source {C}hinese corpus and another five speech recognition datasets --- en.speechocean.com},
        howpublished = {\url{https://en.speechocean.com/Cy/778.html}},
        year = {},
        note = {[Accessed 25-Jun-2023]},
}",,,,,,,,,,,,,,,,,,,
Another reference for the resource,,,"@misc{openslrOpenslrorg,
        author = {Beijing DataTang Technology Co., Ltd},
        title = {aidatatang_200zh},
        howpublished = {\url{http://openslr.org/62/}},
        year = {},
        note = {[Accessed 25-Jun-2023]},
}",,,,,,,,,,,,,,,,,,,
Name mentioned in the previous step,WordNet,WSJ0,AIDATATANG,AISHELL-2,CSJ,HKUST Speech data,,JSUT,VoxForge,AISHELL-ASR0009,LDC Fisher Spanish Speech,LDC Fisher Spanish - Transcripts,The CALLHOME Spanish Speech,The CALLHOME Spanish Transcripts,LibriVox,SWITCHBOARD,TED Talks,LibriVox data of Linda Johnson,CSTR VCTK Corpus English Multi-speaker Corpus for CSTR Voice Cloning Toolkit,DARPA TIMIT,MagnaTune Dataset,FreeSound
original name (if it is written wrongly),,,,,,,,,,,,,,,,,,,,,,
Whose audio/data is it,English Language,Random MIT academics voice recordings,600 speakers from different accent areas in China are invited to participate in the recording.,"1991 speakers: there were
1293 speakers using Northern ones, 678 speakers using
Southern ones and 20 speakers use other accents during
recording.",there are natural sounds and some random people's readings of speech. There is also a dialogue section where people's dialogues are recorded.,the random people who were recruited across China.,random people's phone talks,one female Japanese speaker,people who upload their own speech audio.,"the speakers who were recruited by Beijing Hill Shell Technology Co., Ltd.",136 fluent Spanish speakers randomly recruited for this task. People talking to each other do not previously know each other.,the recruited fluent in Spanish speakers,family and friends of the researchers. They called each other and talked for 10-30 minutes without any pre-determined topic.,family and friends of the researchers. They called each other and talked for 10-30 minutes without any pre-determined topic. The annotations were done by the transcribers funded by Texas Instruments.,volunteers voice recordings while reading chapters of some books,"500 speakers from around the world, they are refered as 'paid volunteers who speak American English'.",volunteers ted talks,Linda Johnson's voice recordings while reading chapters of some books,"109 English speakers with various accents. Speakers were recruited by advertising throughout University of Edinburgh, local newspapers and carers associations. ",The speakers were mainly TI personel. They are in total 630 people and they all read and recorded 10 sentences.,The volunteered artists.,People uploading their songs determine how to tag their songs but they need to provide some necessary information along with it.
"What is the read document/speech content, who does it belong to",English words,it is from Wall Street Journal,"everything from daily speech, machine instructions, voice commands etc.","8 major topics: voice commands such as IoT device control and digital sequential input, places of interest, entertainment, finance, technology, sports, English spellings and free speaking without specific topic. The total number of prompts is around half a million.","wide range of topics are covered from lectures. mock lectures, natural sounds, dialogues, some poems and famous speech read alouds.",People randomly having phone conversations based on the random topic they were given by the automatic operator.,it is given by the automatic operator,"variety of domains such as Japanese characters, onomatopia words, travel related words, songs, mostly utilized Japanese verbs and nouns.",the speech is given by the website,"the speech text is given, its topcs are include wide range of domains: music, TV, movie, finance, voice contral commands, science and technology, physical education etc.",random people are assigned to a random topic which changes every 24 hours.,the content is randomly given by the operator and changes every 24 hours,Most of the conversation was their daily talk.,it was random daily talk between two people who knew each other,the publicly available books ,"they have suggested topics but they do not need to rely on them. After the talk, their hired transcribers transcribe the audio and rate the 'naturalness' of the talk.",the topics the speakers have chosen to give a speech on,the publicly available books ,Herald Glasgow's newspaper texts.,"The text material is 2 dialect ""shibboleth"" sentences designed at SRI, 450 phonetically-compact sentences designed at MIT, and 1890 phonetically-diverse sentences selected at TI.",The songs.,The sounds.
Formal instructions for recording ,lexicographers from different universities filing a form for a word to be grouped in one sub-group. There also is a very long document on it.,"Yes, clearly written in the documentation",Recordings are conducted in a quiet indoor environment and the workers also recorded the speech.,"yes, clearly written in the documentation","yes, they describe it in their documentation",automated operator calling two participants as scheduled to initiate a call,HKUST Speech documentation explains it,they were having meetings with the speaker in 4 different months in 2017. They recorded her voice in our anechoic room. All of the details of the recording instruments were given in their documentation.,They have a short required actions to do to record and a test speech recording in their website. They have a special software which helps people to see and record their own audio.,"yes, it is written in their documentation","yes, there is the operator which is responsible for the recordings","yes, the speakers need to do the calls through a specific channel and need to talk 10 to 12 minutes in total and need to talk about the topic of the day.","recorded by toll-free robot operator maintained originally by Rutgers University, and later by the LDC",yes it was through a robotoperator,the volunteers are allowed to record any good quality way possible,the calls and the recordings are done through 'Robotoperator',"yes, they have a document per every tedtalk that the hosts need to apply.","Not known, she did not specify.","yes, all of the speakers needed to go to the recording place to record their readings of the news text.","Yes, it was given in their documentation in section 3.2 Recording Conditions and Procedures.",Every artist is free to record however they would like to.,Every artist is free to record however they would like to.
Formal instructions for annotating,"there is a hierarchy of lexicographers in the institution, so one request to be considered in a grouping, it needs to go through the hierarchy.",Not necessary,the workers of DataTang have instructions on how to annotate,Not necessary,they have a section on how to transcirbe the speech into Japanese writing. I understood that there are different ways to express some words becuase they have detailed instructions in their manual.,"They only collected audio, no annotation.",they have standards on annotating which was explained in the documentation,Not necessary. The text she read was given.,"Not necessary, people read the given text. Also, people need to annotate themselves in terms of their characteristics before uploading their audio by filling out a form.","yes, it is also written in their documentation","Not necessary, these are not annotated","yes, they have a specific documentation on how to annotate correctly","Not necessary, there are no annotations.","yes, it is written in the documentation. ","Not necessary, the readers are reading the written book chapters",they talk about the protocols utilized while transcribing it in their official documentation.,they have other volunteers who annotate the talks,"Not necessary, she was reading the publicly available books.",The text was read correctly and the people would categorize where they are from and what their accent is by themselves. The researchers also tried to categorize them based on their occupation.,"Not necessary, the people read the pre-defined texts.",People uploading their songs determine how to tag their songs.,People uploading their songs determine how to tag their songs and they also need to provide some additional details on themselves and how they want their sounds to be utilized.
Proof cheking details,the hierarchy ensures this,The people recording are also checking the validity of the sound,the workers annotate and at least double check all of the data. They have special softwares for annotationg and checking the annotations.,The people recording are also checking the validity of the sound,they have a section describing how the proofchecking happens in their documentation,"They only collected audio, no annotation.","they did not mention it, they only mentioned that Hong Kong University of Science and Technology was responsible for it. In a similar project for Spanish corpus which was also online hosted in LDC and has similar authors, the students were utilized for transcriptions, I assume this might is the case for this one as well.",they checked in in the recording,there is a forum where people who are using those audio can comment on it and some other matters with regards tot he website. More than one person is also read the same text.,the person recording and writing are both checking the correctness,not annotated,the annotators have their documents that they need to follow,"a human audit of each telephone call was conducted to verify that the proper language was spoken, to check the quality of the recording, and to select and describe the region to be transcribed.",they have a document stating how the annotation should happen.,There is a proof listener in the website who listens to recordings before they are publsihed to make sure that it is correct and up to the standard. the quality is also determined by the amount of listeners in the website,they give how the annotation has happened and the fact that those people were hired so I assume that they would have some proofchecking methodologies.,there is a hierarchy of annotators so the annotations are checked according to the hierarchy. it is also similar in translations as well.,There is a proof listener in the website who listens to recordings before they are publsihed to make sure that it is correct and up to the standard. the quality is also determined by the amount of listeners in the website,"It is not mentioned but because the people were supposed to read the same text and the people actually need to go to the place to get their recordings, the operator would asl to re-record the passage. All of the speakers were mothertongue English speakers.","after each recording, the operator and the speaker listened to the recording and if there is mispronounciations, they record again.",Not given,flagging feature and the comment section lets user to comment and report the sound if they see it necessary.
Any size details,They try to label all of the owrds in English dictionaries,"27 hours of speech, 15.000 sentences in total, 250.000 words",200 hours of acoustic data,"1000 hours of clean read-speech data from iOS, 1991 speakers","661 hours of lecture data, it took 4 years to transcribe those with 50 workers. ","897 telephone conversations in Mandarin Chinese, 2100 Mandarin speakers","same data, in total of 200 hours of audio data.",10 hours of speech,"They have over 6300 English speech submissions, 2200 French, 2200 Spanish and 1400 German submissions.","3002 hours, 3 million commonly used Chinese sentences",819 telephone conversations of 10 to 12 minutes in duration,819 telephone conversations of 10 to 12 minutes in duration,200 calls 10-30 minutes in length.,200 calls 10-30 minutes in length.,they have nearly 36800 english books and many others in different languages. ,"500 speakers from around the world, the talks did not have a timelimit. It is known that at least 50 of them talked at least an hour.",close to 50.000tedtalks were given since 2009,they have nearly 36800 english books and many others in different languages. ,109 english speakers 400 news paper sentences,"5 hours of speech, each speaker recorded 10 sentences.",Not given,Not given but there is at least 5 different uploads in the last 48 hours.
Detail stating version,Implicit,Explicit,Explicit,Explicit,Explicit,Explicit,Explicit,Explicit,Explicit,Explicit,Explicit,Explicit,Explicit,Explicit,Explicit,Explicit,Explicit,Implicit,Explicit,Explicit,Implicit,Explicit
Reasoning for the stating version,"Their documentation is very long and mostly on how to file a request rather than explaining how the annotation happened at the start or the big contents. It was also hard to reach out to the information that lexicographers from different universities are the ones who acreated this work. The procedure was not apparent in their documentation and their documentation lacks 'the contents' section, therefore to be able to find a section, the reader needs to skim through all of the 86 pages.",Very clear on who they hired and what those people read. They also gave information on the environment they have recorded in. Their documentation was also very clear.,"They are opensource, it is easy to find and download the actual data. They give sufficient amount of information.",very clear documentation on the content and the speaker information of the dataset.,"they have a 574 paged Japanese document explaining who the people whose voices recorded are, the noise audio, all of the style of tagging, the way to annotate the speech and the recording environments. They also mention on how to express the punctiations and how the annotated style needs to be like. ",very clear on speaker information and statistics. They are also clear on the topics and how they recorded the audio of people's phone speeches. ,"it was easy to reach out to the documentation, it was given in the README.txt of their dataset. The data collection strategy and teh content was given. The speaker information and the recordings were also quite clear from the documentation.","very clear documentation on the recording style, the text contents and the process of recording. Each group of content was clearly explained, they also provided why they decided to include that domain.","They are very open in terms of their submission style. They have a community for asking questions and receiving help. They are open on how to create and download submissions. For all of the submission recordings, the detailed information on the speaker is present.",they are very open about the content the dataset contains and the main reason of creating such a dataset. They also give sufficient amount of information on the speakers.,"They are very clear on the speakers, strategy and the topics utilized in their documentation. Their README.txt was also pretty clear. They also give tables of the speaker information.","They are very clear on the people recruited, the annotation description details and the content changing. They also justify their changing contents and their 10-12 minute rule.","Very clear on the speaker information, the context of the talks and the medium the talks happen and how it was recorded. They have a good documentation explaining all of the details and the details of the speakers can be seen in a table as well. ",They have very clear documentation and open source meta data. The documentation informs on how the recording has happened and how the speakers were recruited and initialized. It also informs on who the annotators were and who funded them.,"The website is clear and opensourced. The text that was read was also public domain and anyone can register to publish their recordings. If their recording is not liked, the listeners can choose not to. The data and the labels are very clear.","based on their time 1992, they were very open and clear on the data collection. They also talked about how they automaticize the operator's process. They were willing to give the information on the technologies utilized and the protocols that were given to the speakers.",they are a very open community. The people doing the talks can be searched through and how to volunteer to do the annotation is very clear. The hierarchy for annotations is also a good concept to have as a proof checking. The website has good structure which allows the reader to reach those information easily.,"The issue with this dataset is that it was not referenced properly in the document and it was not apparent whether the 'wildlindajohnson' was actually the author we were looking for. Also, we know that not al of the parts Linda Johnson has read were taken so it is ambiguous which portion of her work was utilized. Mainly due to not being sure 'wildlindajohnson' was her and the portion of teh dataset not known, it was decided implicit. ","Their documentation was clear on how the speakers were reached out, what were the recording conditions and what the read text contained. ","Their documentation is very meticulous on how they find the speakers, what were the texts about and how the recoding happened.",I was unable to download the recordings. The website wanted me to create an account to be able to do so but it was very hard to be forwarded to the signup page instead of login. It was not clear how people decided on the tags and whether there is a checking mechanism for it. The website in general was not very user friendly helping the user to reach to the information easily.,"Very similar to MagnaTune but the difference is that this website is very easy to use and the users are able to give comments and engage with the person uploading the sound. Furthermore, the people uploading their songs has a necessity to add some details on their sound. There are also flagging feature if the sound is not what it says it is. "
Additional notes,,it was recorded in 1991,Their website was sometimes Chinese and sometimes Japanese since they provide datasets for both of those languages. I needed to doublecheck whether I am in the correct version of their website. ,,"their documentation was very long and hard to translate because it was very long. There are also a lot of linguistics information for the people who are responsible for the annotation and because i am not familiar with linguistics nor the Japanese language, I struggled to understand those.",,,,There is a ranking system in the website on the submission qualities but it seems that none of the users have ever used it.,,,,,,,"it was using 1992 technology and I was born in 2000, thus i did not understand the computer and the computer 'Robotoperator' calling both parties through 'T1' channels.",,,,,,